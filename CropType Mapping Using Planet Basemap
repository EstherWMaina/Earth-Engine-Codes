// Load required datasets
var trainingData = ee.FeatureCollection('projects/esther-mainaesther77/assets/FieldData');
var cropMask = ee.Image('projects/esther-mainaesther77/assets/cropmask24');
var planetBasemap = ee.ImageCollection("projects/planet-nicfi/assets/basemaps/africa");

// Print available bands to verify correct names
print("Available bands in Planet NICFI:", planetBasemap.first().bandNames());

// Define crop class mapping
var cropClassMap = {
  'Avocado': 1, 'Bananas': 2, 'Beans': 3, 'Coffee': 4, 'Macadamia': 5,
  'Maize': 6, 'Mango': 7, 'Rice': 8, 'Sorghum': 9, 'Tea': 10, 'Others': 11
};

// Assign numeric crop types
trainingData = trainingData.map(function(feature) {
  var cropName = feature.get('Class');
  var cropID = ee.Dictionary(cropClassMap).get(cropName, 11); // Default: "Others"
  return feature.set('crop_type', ee.Number(cropID));
});

// Print unique crop classes
print("Unique Crop Classes in Training Data:", trainingData.aggregate_array('crop_type').distinct());

// Define Planet NICFI bands
var bands = ['B', 'G', 'R', 'N']; // Blue, Green, Red, Near-Infrared

// Load Planet NICFI Composite
var seasons = planetBasemap.filterDate('2024-11-01', '2024-12-31').select(bands);

// Compute Vegetation Indices for Planet
var ndvi = seasons.mean().normalizedDifference(['N', 'R']).rename('NDVI');
var ndwi = seasons.mean().normalizedDifference(['G', 'N']).rename('NDWI');
var evi = seasons.mean().expression(
  '2.5 * ((N - R) / (N + 6 * R - 7.5 * B + 1))', {
    'N': seasons.mean().select('N'),
    'R': seasons.mean().select('R'),
    'B': seasons.mean().select('B')
}).rename('EVI');

// üõ∞Ô∏è Load Sentinel-2 (To Get Red Edge Band for NDRE)
var sentinel = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
  .filterDate('2024-11-01', '2024-12-31')
  .filterBounds(trainingData.geometry()) // Clip to study area
  .select(['B5', 'B8']) // B5 (Red Edge) and B8 (NIR)
  .median(); // Use median composite

// üåø Compute NDRE: (NIR - RE) / (NIR + RE)
var ndre = sentinel.normalizedDifference(['B8', 'B5']).rename('NDRE');

// üåç Merge Planet + Sentinel-2 Features
var inputImage = seasons.mean().select(bands) // Planet NICFI bands
  .addBands([ndvi, evi, ndwi]) // Planet Indices
  .addBands(ndre); // Sentinel-2 NDRE

// Prepare training data
var labeledData = inputImage.sampleRegions({
  collection: trainingData,
  properties: ['crop_type'],
  scale: 10, // Use Sentinel resolution (10m)
  tileScale: 4
});

// Train a Random Forest Classifier
var classifier = ee.Classifier.smileRandomForest(100).train({
  features: labeledData,
  classProperty: 'crop_type',
  inputProperties: inputImage.bandNames()
});

// Classify the image
var classified = inputImage.classify(classifier);

// Apply crop mask
classified = classified.updateMask(cropMask);

// Visualization
var visParams = {
  min: 1,
  max: 11,
  palette: ['FF0000', '00FF00', '0000FF', 'FFFF00', 'FF00FF', '00FFFF',
            '800000', '808000', '008000', '800080', '808080']
};

// Center map and add layers
Map.centerObject(trainingData, 10);
Map.addLayer(classified, visParams, 'Crop Classification');

// Add a legend
var legend = ui.Panel({style: {position: 'bottom-left', padding: '8px', backgroundColor: 'white'}});
legend.add(ui.Label({value: 'Crop Type Legend', style: {fontWeight: 'bold'}}));

Object.keys(cropClassMap).forEach(function(cropName) {
  var classValue = cropClassMap[cropName];
  var colorBox = ui.Label({style: {backgroundColor: visParams.palette[classValue - 1], padding: '6px', margin: '2px', width: '20px'}});
  var label = ui.Label(cropName);
  var row = ui.Panel([colorBox, label], ui.Panel.Layout.Flow('horizontal'));
  legend.add(row);
});

Map.add(legend);

// Feature Importance Analysis
print('Feature Importance:', classifier.explain().get('importance'));

// Confusion Matrix & Accuracy Metrics
var validation = labeledData.randomColumn().filter(ee.Filter.gt('random', 0.7));
var confusionMatrix = validation.classify(classifier).errorMatrix('crop_type', 'classification');
print('Confusion Matrix:', confusionMatrix);
print('Producer Accuracy:', confusionMatrix.producersAccuracy());
print('User Accuracy:', confusionMatrix.consumersAccuracy());

// Export classified image to Google Drive
Export.image.toDrive({
  image: classified,
  description: 'Crop_Classification',
  scale: 10,
  region: trainingData.geometry(),
  fileFormat: 'GeoTIFF',
  maxPixels: 1e13
});
